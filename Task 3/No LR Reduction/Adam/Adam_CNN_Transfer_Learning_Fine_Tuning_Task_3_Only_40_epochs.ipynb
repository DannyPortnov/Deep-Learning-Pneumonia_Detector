{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhS3l6TBIFsH",
        "outputId": "9e111605-5ff8-458e-ad2c-63f8e161a655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yWpejyuoUk6K"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.applications import ResNet152V2, ResNet50V2\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout, Input\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrR3DTo7TEy7"
      },
      "source": [
        "Generate Data From chest_xray Folder:\n",
        "* Here we split the data in a way that we have bacteria, virus and normal images. in the proper way- some of each and not in a total randomize way\n",
        "* TODO: Need to chek why the depth of the image is 3 and not 1 as in regular cnn network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GZJpDSAaTEy8"
      },
      "outputs": [],
      "source": [
        "# IMG_SIZE = 150\n",
        "IMG_DEPTH = 3\n",
        "IMG_SIZE = 224\n",
        "BATCH = 16\n",
        "SEED = 42\n",
        "\n",
        "normal_dataset = glob.glob('/content/drive/MyDrive/Deep Learning Project/chest_xray/NORMAL/*.jpeg')\n",
        "pneumonia_dataset = glob.glob('/content/drive/MyDrive/Deep Learning Project/chest_xray/PNEUMONIA/*.jpeg')\n",
        "virus_dataset = list(filter(lambda x: 'virus' in x, pneumonia_dataset))\n",
        "bacterial_dataset = list(filter(lambda x: 'bacteria' in x, pneumonia_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urtgR00cTEy9"
      },
      "source": [
        "Generate Train, Validation and Test Sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uID12xDsTEy9"
      },
      "outputs": [],
      "source": [
        "def split_data(dataSet, testSize, valSize):\n",
        "    train, test= train_test_split(dataSet, test_size=testSize, random_state=SEED, shuffle=True)\n",
        "    train, val= train_test_split(train, test_size=valSize, random_state=SEED, shuffle=True)\n",
        "    return train, test, val\n",
        "\n",
        "\n",
        "train_normal, test_normal, val_normal = split_data(normal_dataset, 0.15, 0.038)\n",
        "train_bacterial, test_bacterial, val_bacterial = split_data(bacterial_dataset, 0.05, 0.0095)\n",
        "train_virus, test_virus, val_virus = split_data(virus_dataset, 0.075, 0.019)\n",
        "\n",
        "\n",
        "\n",
        "train = [x for x in train_normal]\n",
        "train.extend([x for x in train_bacterial])\n",
        "train.extend([x for x in train_virus])\n",
        "\n",
        "test = [x for x in test_normal]\n",
        "test.extend([x for x in test_bacterial])\n",
        "test.extend([x for x in test_virus])\n",
        "\n",
        "val = [x for x in val_normal]\n",
        "val.extend([x for x in val_bacterial])\n",
        "val.extend([x for x in val_virus])\n",
        "\n",
        "df_train = pd.DataFrame(np.concatenate([['Normal']*(len(train_normal)) , ['Pneumonia']*(len(train_bacterial) + len(train_virus))]), columns = ['class'])\n",
        "df_train['image'] = [x for x in train]\n",
        "\n",
        "df_val = pd.DataFrame(np.concatenate([['Normal']*(len(val_normal)) , ['Pneumonia']*(len(val_bacterial) + len(val_virus))]), columns = ['class'])\n",
        "df_val['image'] = [x for x in val]\n",
        "\n",
        "df_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*(len(test_bacterial) + len(test_virus))]), columns = ['class'])\n",
        "df_test['image'] = [x for x in test]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycjEOBYfTEy-"
      },
      "source": [
        "Perform Data Augmentation on Each Set:\n",
        "* TODO: Need to check why we are doing data augmentation on all 3 sets\n",
        "  and not just on the training set as in the regular cnn network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osKNQr3TTEy-",
        "outputId": "7b2befb0-d179-4528-a81c-9bf207dd34a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5262 validated image filenames belonging to 2 classes.\n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Found 489 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# With data augmentation to prevent overfitting and handling the imbalance in dataset\n",
        "# Because the dataset is small we \"increase\" the dataset by change of images parameters.\n",
        "# In this way we increase our dataset and prevent overfitting.\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "                                  zoom_range = 0.1,\n",
        "                                  #rotation_range = 0.1,\n",
        "                                  width_shift_range = 0.1,\n",
        "                                  height_shift_range = 0.1)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "ds_train = train_datagen.flow_from_dataframe(df_train,\n",
        "                                             #directory=train_path, #dataframe contains the full paths\n",
        "                                             x_col = 'image',\n",
        "                                             y_col = 'class',\n",
        "                                             target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                             class_mode = 'binary',\n",
        "                                             batch_size = BATCH,\n",
        "                                             seed = SEED)\n",
        "\n",
        "ds_val = test_datagen.flow_from_dataframe(df_val,\n",
        "                                            #directory=train_path,\n",
        "                                            x_col = 'image',\n",
        "                                            y_col = 'class',\n",
        "                                            target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                            class_mode = 'binary',\n",
        "                                            batch_size = BATCH,\n",
        "                                            seed = SEED)\n",
        "\n",
        "ds_test = test_datagen.flow_from_dataframe(df_test,\n",
        "                                            #directory=test_path,\n",
        "                                            x_col = 'image',\n",
        "                                            y_col = 'class',\n",
        "                                            target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                            class_mode = 'binary',\n",
        "                                            batch_size = 1,\n",
        "                                            shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IavaJCpaTEy_"
      },
      "source": [
        "# Building CNN Network- Transfer Learning with Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etEypy1RTEy_"
      },
      "source": [
        "Create and Freeze the Base Model and Get the Pre-Trained Model\n",
        "* This function creates a base model and freezeing all of its layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hH_eidsOTEy_"
      },
      "outputs": [],
      "source": [
        "def create_base_model():\n",
        "    # --------- create base model ----------#\n",
        "    base_model = ResNet50V2(\n",
        "        weights='imagenet',\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, IMG_DEPTH),\n",
        "        include_top=False)\n",
        "\n",
        "    # --------- FREEZE base model ----------#\n",
        "    base_model.trainable = False\n",
        "    return base_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3LabjQeTEy_"
      },
      "source": [
        "Get the Pre-Trained Model\n",
        "* If you are creating many models in a loop, this global state will consume\n",
        "  an increasing amount of memory over time, and you may want to clear it.\n",
        "  Calling clear_session() releases the global state: this helps avoid clutter\n",
        "  from old models and layers, especially when memory is limited.\n",
        "* We use: keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZPSQ8JobTEy_"
      },
      "outputs": [],
      "source": [
        "def get_pre_trained_model(base_model):\n",
        "    # --------- get pretrained model ----------#\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    #Input shape = [width, height, color channels]\n",
        "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, IMG_DEPTH))\n",
        "\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    # Head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    #Final Layer (Output)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    pre_trained_model = keras.Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    return pre_trained_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI6NCaUJTEzA"
      },
      "source": [
        "Adding Fine Tuning\n",
        "* This function un-freezes the top layers of the base model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jrkkA3MOTEzA"
      },
      "outputs": [],
      "source": [
        "def add_fine_tuning(base_model):\n",
        "    # Set the base_model as trainable\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Print the number of layers in the base_model\n",
        "    print(f\"Number of Layers In the Base Model: {len(base_model.layers)}\")\n",
        "\n",
        "    # Specify the layer index from which fine-tuning will start\n",
        "    fine_tune_from = -70\n",
        "\n",
        "    # Iterate through the layers of the base_model\n",
        "    # and set them as non-trainable up to the fine_tune_from index\n",
        "    for layer in base_model.layers[:fine_tune_from]:\n",
        "        layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMimp8KeTEzA"
      },
      "source": [
        "Try Different Epochs and Learning Rates\n",
        "* Compile and Train the Model for each Epoch and Learning Rate.\n",
        "\n",
        "* Plot Graphs of the Training and Validation Accuracy and Loss vs Epochs.\n",
        "\n",
        "* It is critical to only do fine tuning after the model with frozen layers has been trained to convergence.\n",
        "  If you mix randomly-initialized trainable layers with trainable layers that hold pre-trained features,\n",
        "  the randomly-initialized layers will cause very large gradient updates during training, which will destroy your pre-trained features.\n",
        "\n",
        "* It's also critical to use a very low learning rate at this stage, because you are training a much larger model than in the first round of training, on a dataset that is typically very small. As a result, you are at risk of overfitting very quickly if you apply large weight updates. Here, you only want to readapt the pretrained weights in an incremental way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZGfeX-7TEzA",
        "outputId": "e70438c4-a765-4527-a1ea-4a7f935ee375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "328/328 [==============================] - 132s 391ms/step - loss: 0.3112 - accuracy: 0.9105 - val_loss: 0.1957 - val_accuracy: 0.9048\n",
            "Epoch 2/20\n",
            "328/328 [==============================] - 127s 387ms/step - loss: 0.1578 - accuracy: 0.9445 - val_loss: 0.1151 - val_accuracy: 0.9619\n",
            "Epoch 3/20\n",
            "328/328 [==============================] - 130s 397ms/step - loss: 0.1552 - accuracy: 0.9434 - val_loss: 0.1366 - val_accuracy: 0.9714\n",
            "Epoch 4/20\n",
            "328/328 [==============================] - 127s 387ms/step - loss: 0.1528 - accuracy: 0.9432 - val_loss: 0.1182 - val_accuracy: 0.9524\n",
            "Epoch 5/20\n",
            "328/328 [==============================] - 126s 382ms/step - loss: 0.1580 - accuracy: 0.9394 - val_loss: 0.0919 - val_accuracy: 0.9619\n",
            "Epoch 6/20\n",
            "328/328 [==============================] - 126s 382ms/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.0904 - val_accuracy: 0.9714\n",
            "Epoch 7/20\n",
            "328/328 [==============================] - 126s 383ms/step - loss: 0.1403 - accuracy: 0.9472 - val_loss: 0.0845 - val_accuracy: 0.9714\n",
            "Epoch 8/20\n",
            "328/328 [==============================] - 126s 382ms/step - loss: 0.1374 - accuracy: 0.9464 - val_loss: 0.1092 - val_accuracy: 0.9429\n",
            "Epoch 9/20\n",
            "328/328 [==============================] - 128s 389ms/step - loss: 0.1312 - accuracy: 0.9515 - val_loss: 0.0923 - val_accuracy: 0.9524\n",
            "Epoch 10/20\n",
            "328/328 [==============================] - 130s 394ms/step - loss: 0.1455 - accuracy: 0.9474 - val_loss: 0.0837 - val_accuracy: 0.9714\n",
            "Epoch 11/20\n",
            "328/328 [==============================] - 128s 390ms/step - loss: 0.1467 - accuracy: 0.9458 - val_loss: 0.0926 - val_accuracy: 0.9619\n",
            "Epoch 12/20\n",
            "328/328 [==============================] - 130s 394ms/step - loss: 0.1241 - accuracy: 0.9544 - val_loss: 0.0840 - val_accuracy: 0.9810\n",
            "Epoch 13/20\n",
            "328/328 [==============================] - 130s 395ms/step - loss: 0.1164 - accuracy: 0.9532 - val_loss: 0.0906 - val_accuracy: 0.9619\n",
            "Epoch 14/20\n",
            "328/328 [==============================] - 131s 398ms/step - loss: 0.1257 - accuracy: 0.9513 - val_loss: 0.0616 - val_accuracy: 0.9905\n",
            "Epoch 15/20\n",
            "328/328 [==============================] - 130s 395ms/step - loss: 0.1330 - accuracy: 0.9502 - val_loss: 0.0894 - val_accuracy: 0.9524\n",
            "Epoch 16/20\n",
            "328/328 [==============================] - 130s 396ms/step - loss: 0.1246 - accuracy: 0.9561 - val_loss: 0.1131 - val_accuracy: 0.9619\n",
            "Epoch 17/20\n",
            "328/328 [==============================] - 128s 391ms/step - loss: 0.1280 - accuracy: 0.9532 - val_loss: 0.1399 - val_accuracy: 0.9619\n",
            "Epoch 18/20\n",
            "328/328 [==============================] - 130s 394ms/step - loss: 0.1382 - accuracy: 0.9494 - val_loss: 0.0919 - val_accuracy: 0.9524\n",
            "Epoch 19/20\n",
            "328/328 [==============================] - 129s 393ms/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.0922 - val_accuracy: 0.9619\n",
            "Epoch 20/20\n",
            "328/328 [==============================] - 129s 393ms/step - loss: 0.1577 - accuracy: 0.9388 - val_loss: 0.1498 - val_accuracy: 0.9524\n",
            "Number of Layers In the Base Model: 190\n",
            "Epoch 20/40\n",
            "328/328 [==============================] - 138s 406ms/step - loss: 8.4351 - accuracy: 0.7419 - val_loss: 0.7570 - val_accuracy: 0.5048\n",
            "Epoch 21/40\n",
            "328/328 [==============================] - 131s 398ms/step - loss: 0.5675 - accuracy: 0.7543 - val_loss: 0.7799 - val_accuracy: 0.5048\n",
            "Epoch 22/40\n",
            "328/328 [==============================] - 131s 399ms/step - loss: 0.5617 - accuracy: 0.7543 - val_loss: 0.8000 - val_accuracy: 0.5048\n",
            "Epoch 23/40\n",
            "328/328 [==============================] - 131s 398ms/step - loss: 0.5592 - accuracy: 0.7543 - val_loss: 0.8140 - val_accuracy: 0.5048\n",
            "Epoch 24/40\n",
            "328/328 [==============================] - 130s 395ms/step - loss: 0.5582 - accuracy: 0.7543 - val_loss: 0.8231 - val_accuracy: 0.5048\n",
            "Epoch 25/40\n",
            "328/328 [==============================] - 130s 395ms/step - loss: 0.5578 - accuracy: 0.7543 - val_loss: 0.8294 - val_accuracy: 0.5048\n",
            "Epoch 26/40\n",
            "328/328 [==============================] - 130s 396ms/step - loss: 0.5577 - accuracy: 0.7543 - val_loss: 0.8320 - val_accuracy: 0.5048\n",
            "Epoch 27/40\n",
            "328/328 [==============================] - 130s 397ms/step - loss: 0.5577 - accuracy: 0.7543 - val_loss: 0.8344 - val_accuracy: 0.5048\n",
            "Epoch 28/40\n",
            "328/328 [==============================] - 131s 397ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8348 - val_accuracy: 0.5048\n",
            "Epoch 29/40\n",
            "328/328 [==============================] - 131s 397ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8365 - val_accuracy: 0.5048\n",
            "Epoch 30/40\n",
            "328/328 [==============================] - 128s 390ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8359 - val_accuracy: 0.5048\n",
            "Epoch 31/40\n",
            "328/328 [==============================] - 129s 392ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8365 - val_accuracy: 0.5048\n",
            "Epoch 32/40\n",
            "328/328 [==============================] - 131s 397ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8365 - val_accuracy: 0.5048\n",
            "Epoch 33/40\n",
            "328/328 [==============================] - 130s 395ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8370 - val_accuracy: 0.5048\n",
            "Epoch 34/40\n",
            "328/328 [==============================] - 129s 393ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8378 - val_accuracy: 0.5048\n",
            "Epoch 35/40\n",
            "328/328 [==============================] - 128s 390ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8369 - val_accuracy: 0.5048\n",
            "Epoch 36/40\n",
            "328/328 [==============================] - 131s 399ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8370 - val_accuracy: 0.5048\n",
            "Epoch 37/40\n",
            "328/328 [==============================] - 133s 403ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.8377 - val_accuracy: 0.5048\n",
            "Epoch 38/40\n",
            " 44/328 [===>..........................] - ETA: 1:54 - loss: 0.5576 - accuracy: 0.7543"
          ]
        }
      ],
      "source": [
        "Epochs = [40]\n",
        "learning_rates= [0.01, 0.001, 0.0001]\n",
        "\n",
        "opt = Adam\n",
        "\n",
        "lr_epoch_test_acc = {}\n",
        "lr_epoch_test_loss = {}\n",
        "for Epoch in Epochs:\n",
        "  initial_epochs = Epoch//2\n",
        "  for lr in learning_rates:\n",
        "    base_model = create_base_model()\n",
        "    model = get_pre_trained_model(base_model)\n",
        "    # Training the model with all layers frozen\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer = opt(learning_rate=lr), metrics='accuracy')\n",
        "    # model.summary()\n",
        "    history = model.fit(ds_train,\n",
        "            batch_size=BATCH, epochs=initial_epochs,\n",
        "            validation_data=ds_val,\n",
        "            steps_per_epoch=(len(df_train)/BATCH),\n",
        "            validation_steps=(len(df_val)/BATCH))\n",
        "    # Evaluate the Accuracy and Loss (Before Fine Tuning)\n",
        "    train_acc = history.history['accuracy']\n",
        "    train_loss = history.history['loss']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # adding fine tuning\n",
        "    add_fine_tuning(base_model)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer = opt(learning_rate=lr/10), metrics='accuracy')\n",
        "    history_fine = model.fit(ds_train,\n",
        "                        batch_size=BATCH,\n",
        "                        epochs=Epoch,\n",
        "                        initial_epoch=history.epoch[-1],\n",
        "                        validation_data=ds_val,\n",
        "                        steps_per_epoch=(len(df_train)/BATCH),\n",
        "                        validation_steps=(len(df_val)/BATCH))\n",
        "    # Evaluate the Accuracy and Loss (After Fine Tuning):\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(ds_test, verbose=0)\n",
        "    lr_epoch_tuple = (Epoch, lr)\n",
        "    lr_epoch_test_acc[lr_epoch_tuple] = test_accuracy\n",
        "    lr_epoch_test_loss[lr_epoch_tuple] = test_loss\n",
        "    print(\"Test Loss:\", test_loss)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    train_acc += history_fine.history['accuracy']\n",
        "    val_acc += history_fine.history['val_accuracy']\n",
        "    train_loss += history_fine.history['loss']\n",
        "    val_loss += history_fine.history['val_loss']\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "    # Create a figure and subplot\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    # Plot the training and validation accuracy\n",
        "    axs[0].plot(train_acc, 'bo-', label='Training Accuracy')\n",
        "    axs[0].plot(val_acc, 'ro-', label='Validation Accuracy')\n",
        "    axs[0].set_title(f'Training & Validation Accuracy\\n opt={opt.__name__}, lr={lr}, Epochs={Epoch}')\n",
        "    # axs[0].title.set_size(10) # if title is too big, change the size here\n",
        "    axs[0].legend(loc='lower right')\n",
        "    axs[0].set_xlabel(\"Epochs\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "    # Plot the training and validation loss\n",
        "    axs[1].plot(train_loss, 'bo-', label='Training Loss')\n",
        "    axs[1].plot(val_loss, 'ro-', label='Validation Loss')\n",
        "    axs[1].set_title(f'Training & Validation Loss\\n opt={opt.__name__}, lr={lr}, Epochs={Epoch}')\n",
        "    # axs[1].title.set_size(10) # if title is too big, change the size here\n",
        "    axs[1].legend(loc='upper right')\n",
        "    axs[1].set_xlabel(\"Epochs\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "\n",
        "    # Adjust spacing between subplots\n",
        "    plt.subplots_adjust(wspace=0.2)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTp6dOXtTEzB"
      },
      "source": [
        "Print the Loss & Accuracy Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN2NyNysTEzB"
      },
      "outputs": [],
      "source": [
        "print(f\"Test Accuracy and Loss Results with Optimizer: {opt.__name__}\")\n",
        "print()\n",
        "print()\n",
        "def print_results_dict(Accuracy, Loss):\n",
        "    print(\"Print Accuracy Results\")\n",
        "    for key, val in Accuracy.items():\n",
        "        epochs, lr = key\n",
        "        print(f\"Epochs Number = {epochs}, Learning Rate = {lr}, Accuracy = {val:.3f}\")\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Print Loss Results\")\n",
        "    for key, val in Loss.items():\n",
        "        epochs, lr = key\n",
        "        print(f\"Epochs Number = {epochs}, Learning Rate = {lr}, Loss = {val:.3f}\")\n",
        "\n",
        "\n",
        "print_results_dict(lr_epoch_test_acc, lr_epoch_test_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}